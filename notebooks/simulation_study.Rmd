---
title: "Simulation study - Poisson Lognormal model"
output:
  html_document:
    df_print: paged
---

```{r}
library(kableExtra)
library(ggplot2)
library(dplyr)
library(tidyr)
library(rstudioapi)
library(IsoPriceR)
library(readr)
library(xtable)
library(latex2exp)
setwd(dirname(getActiveDocumentContext()$path))
getwd()
```


We assume the risk is distributed according to the following model 

$$
X \sim \text{Poisson}(\lambda =0.7)-\text{Lognormal}(\mu = 5.7, \sigma = 1)
$$
We aim at recovering the parameters based on simulated commercial rate defined as 
$$
\pi_i = (1+\eta_i)\mathbb{E}[g_i(X)] = (1+\eta_i)\mathbb{E}\{\text{min}[\text{max}(r_i\cdot X - d_i, 0), l_i]\}
$$
We have collected rates from various insurance company associated to an health insurance product for pets. As we would like our simulation study to inform the real data analysis of the next section we generate data by shuffling the rate, deductible and limits present in the real data to produce many samples of commercial premiums. The safety loading is sampled uniformly as 
$$
\eta_i\sim\text{Unif}([0.42, 1.5])
$$
which corresponds to a loss ratio between $0.4$ and $0.7$. We aim at looking at the convergence of our estimator so the sample size of the synthetic data increases as $n\{50, 100, 250, 500\}$.

# First Run

```{r}
#One simulation for the fun to superpose the posterior distributions
# Data ----
pet_insurance_FR <- read_csv("../data/pet_insurance_FR.csv")
data_pet_insurance <- data.frame(carrier = pet_insurance_FR$Company, race = pet_insurance_FR$Race,
                                 r = as.numeric(sub("%", "", pet_insurance_FR$rate))/100,
                                 d = pet_insurance_FR$deductible,
                                 l = pet_insurance_FR$limit,
                                 x = pet_insurance_FR$Premium)
# Sample sizes----
ns <- c( 50, 100, 250, 500)
# ns <- c(50)


# Premium an loss model Settings ----
p_p <- pure_premium("xs", c("r", "d", "l"))
freq_dist <- model("poisson", c("lambda"))
sev_dist <- model("lognormal", c("mu", "sigma"))
l_m <- loss_model(freq_dist, sev_dist, "Lognormal(mu, sigma = 1)-Poisson(lambda)")

# True parameters of the loss model ----
lambda_true <- 0.58; mu_true <- 5.75; sigma_true <- 1
true_parms <- t(as.matrix(c(lambda_true, mu_true, sigma_true)))
colnames(true_parms) <- l_m$parm_names

# Prior assumptions----
prior_lambda <- prior_dist("uniform", "lambda",c(0, 10))
prior_mu <- prior_dist("uniform", "mu",c(-10, 10))
prior_sigma <- prior_dist("constant", "sigma", c(1))
prior_distributions <- list(prior_lambda, prior_mu, prior_sigma)
model_prior <- independent_priors(prior_distributions)
# 
set.seed(12345)
# Fake Data
# d <- sample(data_pet_insurance$d, max(ns), replace = TRUE)
# l <- sample(data_pet_insurance$l, max(ns), replace = TRUE)
# r <- sample(data_pet_insurance$r, max(ns), replace = TRUE)
# th_premium <- matrix(c(r, d, l), nrow = max(ns))
# data <- as.data.frame(th_premium); colnames(data) <- p_p$parm_names
# X_true <- sample_X(l_m, true_parms, R = 10000)
# data["pp"] <- compute_pure_premia(X_true, coverage_type = "xs", th_premium)
# lr <- runif(max(ns) ,0.4, 0.7)
# data["x"] <- data["pp"] / lr
# popSize=1000;  MC_R=2000; acc = 1; sp_bounds = c(0.4, 0.7)
# res_abc <- lapply(ns, function(n) abc(data[1:n,], model_prior, l_m, p_p, popSize,  MC_R, acc, sp_bounds))
# save(data, file = "../data/data_sim.RData")
# save(res_abc, file = "../data/res_abc_sim.RData")
```

```{r}
load("../data/data_sim.RData")
load("../data/res_abc_sim.RData")
res_abc_sim <- res_abc
data_sim <- data
# best_clouds <- lapply(res_abc_sim, function(res_abc) extract_best_cloud(res_abc))
best_clouds <- lapply(res_abc_sim, function(res_abc) extract_last_cloud(res_abc))
best_cloud_df <- data.frame()

max(res_abc_sim[[1]]$ds[[length(res_abc_sim[[1]]$ds)]]);max(res_abc_sim[[2]]$ds[[length(res_abc_sim[[2]]$ds)]])

for(k in 1:length(ns)){
  best_cloud <- as.data.frame(best_clouds[[k]])
  best_cloud["ss"] <- ns[k]
  best_cloud_df <- rbind(best_cloud_df, best_cloud)
}

(post_lambda <- ggplot2::ggplot(best_cloud_df) + ggplot2::geom_density(mapping = aes(x= lambda, group = as.factor(ss) , color = as.factor(ss))) +   ggplot2::geom_vline(ggplot2::aes(xintercept=lambda_true),color="black", linetype="dashed") + ggplot2::labs(x= TeX(r'($\lambda$)'), color = "Sample size", y = "") + ggplot2::theme_classic(base_size = 20) + ggplot2::theme(legend.position="right"))
ggsave("../figures/post_lambda_sim_1.pdf", post_lambda)

(post_mu <- ggplot2::ggplot(best_cloud_df) + ggplot2::geom_density(mapping = aes(x= mu, group = as.factor(ss) , color = as.factor(ss))) +   ggplot2::geom_vline(ggplot2::aes(xintercept=mu_true),color="black", linetype="dashed") + ggplot2::labs(x= TeX(r'($\mu$)'), color = "Sample size",  y = "") + ggplot2::theme_classic(base_size = 20) + ggplot2::theme(legend.position="right"))
ggsave("../figures/post_mu_sim_1.pdf", post_mu)
```


```{r}
# post_metrics_df <- data.frame()
# 
# for(k in 1:length(ns)){
#   best_cloud <- best_clouds[[k]]
#   res <- compute_metric_cloud(data[1:ns[k],], p_p, l_m, best_cloud)$estimates
#   res["ss"] <- ns[k]
#   post_metrics_df <- rbind(post_metrics_df, res)
# }
# save(post_metrics_df, file = "../data/post_metrics_df_sim_1.RData")
load("../data/post_metrics_df_sim_1.RData")

quantity_true <- compute_metric_particle(data, p_p, l_m, true_parms, method = "none")$estimates
quantity_true <- quantity_true %>% mutate(parm_values = ifelse(parm_names == "LR", 0.55, parm_values))

quantity_titles <- c(  "Claim Frequency","Claim Amount","P(N=0)", "Total Claim Amount","Loss Ratio" )
i <- 1
quantity <- colnames(post_metrics_df)[2:6][i]
for(quantity in colnames(post_metrics_df)[2:6]){
  
  (post_boxplot <- ggplot(data = post_metrics_df %>% select(quantity, ss)) + 
     geom_boxplot(mapping = aes(y = eval(parse(text=quantity)) , x = as.factor(ss), color = as.factor(ss))) + 
     geom_hline(data = quantity_true %>%filter(parm_names == quantity) ,aes(yintercept=parm_values),
                color="black", linetype="dashed") + 
     theme_classic(base_size = 20) + theme(legend.position="right") + labs(x= "Sample size",  title = quantity_titles[i], y = "", color = "Sample size"))
  i <- i+1
  ggsave(paste0("../figures/post_boxplot_simu_1_",quantity, ".pdf"), post_boxplot)
}

```



# All Runs
```{r}
# The result coming from the server
df_sim <- read_csv("../data/res_sim.csv")
parm_true <- t(as.matrix(c(lambda_true, mu_true, sigma_true)))
names(parm_true) <- l_m$parm_names
quantity_true <- compute_metric_particle(data, p_p, l_m, true_parms, method = "none")$estimates
quantity_true <- quantity_true %>% mutate(parm_values = ifelse(parm_names == "LR", 0.55, parm_values))

quantity_titles <- c(TeX(r'($\lambda$)'), TeX(r'($\mu$)'), "Sigma", "P(N=0)", "Loss Ratio", "Claim Frequency", "Claim Amount", "Total Claim Amount" )

i   <- 1
quantity <- quantity_true$parm_names[i]
for(quantity in quantity_true$parm_names){
  (post_boxplot <- ggplot(data = df_sim %>% filter(parm_names == quantity)) + geom_boxplot(mapping = aes(y = parm_values, x = as.factor(ss), color = method)) + ggplot2::geom_hline(data = quantity_true %>%filter(parm_names == quantity) ,ggplot2::aes(yintercept=parm_values),color="black", linetype="dashed") + ggplot2::theme_classic(base_size = 20) + ggplot2::theme(legend.position="right") + ggplot2::labs(x= "Sample size", color = "",  title = quantity_titles[i], y = ""))
i <- i + 1
  ggsave(paste0("../figures/post_boxplot_simu_All_",quantity, ".pdf"), post_boxplot)
}

````


